# AUTOGENERATED! DO NOT EDIT! File to edit: ../notebooks/api/01_renderers.ipynb.

# %% auto 0
__all__ = ['Siddon', 'Trilinear']

# %% ../notebooks/api/01_renderers.ipynb 3
import torch
from torch.nn.functional import grid_sample

# %% ../notebooks/api/01_renderers.ipynb 7
class Siddon(torch.nn.Module):
    """Differentiable X-ray renderer implemented with Siddon's method for exact raytracing."""

    def __init__(
        self,
        mode="nearest",
        eps=1e-8,
    ):
        super().__init__()
        self.mode = mode
        self.eps = eps

    def dims(self, volume):
        return torch.tensor(volume.shape).to(volume) + 1

    def forward(
        self,
        volume,
        origin,
        spacing,
        source,
        target,
        align_corners=True,
        mask=None,
    ):
        dims = self.dims(volume)
        origin = origin.to(
            torch.float64
        )  # Somehow improves rendering quality (see https://github.com/eigenvivek/DiffDRR/issues/202)

        # Calculate the intersections of each ray with the planes of the CT volume
        alphas = _get_alphas(source, target, origin, spacing, dims, self.eps)

        # Calculate the midpoint of every adjacent intersection point (exclusively in one voxel)
        alphamid = (alphas[..., 0:-1] + alphas[..., 1:]) / 2

        # Get the XYZ coordinate of each midpoint
        xyzs = _get_xyzs(alphamid, source, target, origin, spacing, dims, self.eps)

        # Use torch.nn.functional.grid_sample to lookup the values of each voxel
        img = _get_voxel(volume, xyzs, self.mode, align_corners)

        # Weight each voxel by the length of the ray's intersection with the voxel
        step_length = torch.diff(alphas, dim=-1)
        img = img * step_length

        # Handle optional masking
        if mask is None:
            img = img.sum(dim=-1)
            img = img.unsqueeze(1)
        else:
            # Thanks to @Ivan for the clutch assist w/ pytorch tensor ops
            # https://stackoverflow.com/questions/78323859/broadcast-pytorch-array-across-channels-based-on-another-array/78324614#78324614
            B, D, _ = img.shape
            C = mask.max().item() + 1
            channels = _get_voxel(
                mask.to(torch.float32), xyzs, aligned_corners=align_corners
            ).long()
            img = (
                torch.zeros(B, C, D)
                .to(volume)
                .scatter_add_(1, channels.transpose(-1, -2), img.transpose(-1, -2))
            )

        # Multiply by ray length such that the proportion of attenuated energy is unitless
        raylength = (target - source + self.eps).norm(dim=-1)
        img *= raylength.unsqueeze(1)
        return img

# %% ../notebooks/api/01_renderers.ipynb 8
def _get_alphas(source, target, origin, spacing, dims, eps):
    """Calculates the parametric intersections of each ray with the planes of the CT volume."""
    # Get the CT sizing and spacing parameters
    alphax = torch.arange(dims[0]).to(source) * spacing[0] + origin[0]
    alphay = torch.arange(dims[1]).to(source) * spacing[1] + origin[1]
    alphaz = torch.arange(dims[2]).to(source) * spacing[2] + origin[2]

    # Get the alpha at each plane intersection
    sdd = target - source + eps
    sx, sy, sz = source[..., 0], source[..., 1], source[..., 2]
    alphax = alphax.expand(len(source), 1, -1) - sx.unsqueeze(-1)
    alphay = alphay.expand(len(source), 1, -1) - sy.unsqueeze(-1)
    alphaz = alphaz.expand(len(source), 1, -1) - sz.unsqueeze(-1)
    alphax = alphax / sdd[..., 0].unsqueeze(-1)
    alphay = alphay / sdd[..., 1].unsqueeze(-1)
    alphaz = alphaz / sdd[..., 2].unsqueeze(-1)
    alphas = torch.cat([alphax, alphay, alphaz], dim=-1)

    # Sort the intersections
    alphas = torch.sort(alphas, dim=-1).values
    return alphas


def _get_xyzs(alpha, source, target, origin, spacing, dims, eps):
    """Given a set of rays and parametric coordinates, calculates the XYZ coordinates."""
    xyzs = (
        source.unsqueeze(2)
        + alpha.unsqueeze(-1) * (target - source + eps).unsqueeze(2)
        - origin.to(torch.float32)
    )
    # Use inplace operations to minimize memory overhead
    xyzs.mul_(2).div_(spacing * dims).sub_(1)
    return xyzs


def _get_voxel(volume, xyzs, mode="nearest", aligned_corners=True):
    """Wraps torch.nn.functional.grid_sample to sample a volume at XYZ coordinates."""
    volume = volume.permute(2, 1, 0)
    batch_size = len(xyzs)
    voxels = grid_sample(
        input=volume[None, None, :, :, :].expand(batch_size, -1, -1, -1, -1),
        grid=xyzs.unsqueeze(1),
        mode=mode,
        align_corners=aligned_corners,
    )[:, 0, 0]
    return voxels

# %% ../notebooks/api/01_renderers.ipynb 10
class Trilinear(torch.nn.Module):
    """Differentiable X-ray renderer implemented with trilinear interpolation."""

    def __init__(
        self,
        near=0.0,
        far=1.0,
        mode="bilinear",
        eps=1e-8,
    ):
        super().__init__()
        self.near = near
        self.far = far
        self.mode = mode
        self.eps = eps

    def dims(self, volume):
        return torch.tensor(volume.shape).to(volume) + 1

    def forward(
        self,
        volume,
        origin,
        spacing,
        source,
        target,
        n_points=500,
        align_corners=True,
        mask=None,
    ):
        # Get the raylength and reshape sources
        raylength = (source - target + self.eps).norm(dim=-1).unsqueeze(1)

        # Sample points along the rays and rescale to [-1, 1]
        alphas = torch.linspace(self.near, self.far, n_points).to(volume)
        alphas = alphas[None, None, :]

        # Render the DRR
        dims = self.dims(volume)
        xyzs = _get_xyzs(alphas, source, target, origin, spacing, dims, self.eps)
        img = _get_voxel(volume, xyzs, self.mode, align_corners)

        # Handle optional masking
        if mask is None:
            img = img.sum(dim=-1).unsqueeze(1)
        else:
            B, D, _ = img.shape
            C = mask.max().item() + 1
            channels = _get_voxel(mask.to(torch.float32), xyzs, align_corners).long()
            img = (
                torch.zeros(B, C, D)
                .to(volume)
                .scatter_add_(1, channels.transpose(-1, -2), img.transpose(-1, -2))
            )

        # Multiply by raylength
        img *= raylength / n_points
        return img
