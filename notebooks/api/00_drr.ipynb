{
 "cells": [
  {
   "cell_type": "raw",
   "id": "12e70d79",
   "metadata": {},
   "source": [
    "---\n",
    "title: DRR\n",
    "description: Module for computing digitally reconstructed radiographs\n",
    "output-file: drr.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp drr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5be32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95e1ac-413e-407b-87ad-0c7db3a945de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastcore.basics import patch\n",
    "\n",
    "from diffdrr.detector import Detector\n",
    "from diffdrr.renderers import Siddon, Trilinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd42817-b14a-42a4-bf73-c7ea4da2890c",
   "metadata": {},
   "source": [
    "## DRR\n",
    "`DRR` is a PyTorch module that compues differentiable digitally reconstructed radiographs. The viewing angle for the DRR (known generally in computer graphics as the *camera pose*) is parameterized by the following parameters:\n",
    "\n",
    "- SDR : Source-to-Detector radius (half of the source-to-detector distance)\n",
    "- $\\mathbf R \\in \\mathrm{SO}(3)$ : a rotation\n",
    "- $\\mathbf t \\in \\mathbb R^3$ : a translation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a266460-9b18-4f8a-9bee-d78834b4ff0d",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "`DiffDRR` can take a rotation parameterized in any of the following forms to move the detector plane:\n",
    "\n",
    "- `axis_angle`\n",
    "- `euler_angles` (note: also need to specify the `convention` for the Euler angles)\n",
    "- `matrix`\n",
    "- `quaternion` \n",
    "- `quaternion_adjugate` ([Hanson and Hanson, 2022](https://arxiv.org/abs/2205.09116))\n",
    "- `rotation_6d` ([Zhou et al., 2019](https://arxiv.org/abs/1812.07035))\n",
    "- `rotation_10d` ([Peretroukhin et al., 2021](https://arxiv.org/abs/2006.01031))`\n",
    "- `se3_log_map`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc09da-a788-4d2d-a780-c84a1e9c6bb6",
   "metadata": {},
   "source": [
    "If using Euler angles, the parameters are\n",
    "\n",
    "- `alpha`      : Azimuthal angle\n",
    "- `beta`       : Polar angle\n",
    "- `gamma`      : Plane rotation angle\n",
    "- `bx`         : X-dir translation\n",
    "- `by`         : Y-dir translation\n",
    "- `bz`         : Z-dir translation\n",
    "- `convention` : Order of angles (e.g., `ZYX`)\n",
    "\n",
    "`(bx, by, bz)` are translational parameters and `(alpha, beta, gamma)` are rotational parameters. The rotational parameters are detailed in [Spherical Coordiantes Tutorial](https://vivekg.dev/DiffDRR/tutorials/spherical.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97297d06-6772-4dc7-8af5-d1ea7b379d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DRR(nn.Module):\n",
    "    \"\"\"PyTorch module that computes differentiable digitally reconstructed radiographs.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        volume: np.ndarray,  # CT volume\n",
    "        spacing: np.ndarray,  # Dimensions of voxels in the CT volume\n",
    "        sdr: float,  # Source-to-detector radius for the C-arm (half of the source-to-detector distance)\n",
    "        height: int,  # Height of the rendered DRR\n",
    "        delx: float,  # X-axis pixel size\n",
    "        width: int | None = None,  # Width of the rendered DRR (default to `height`)\n",
    "        dely: float | None = None,  # Y-axis pixel size (if not provided, set to `delx`)\n",
    "        x0: float = 0.0,  # Principal point X-offset\n",
    "        y0: float = 0.0,  # Principal point Y-offset\n",
    "        p_subsample: float | None = None,  # Proportion of pixels to randomly subsample\n",
    "        reshape: bool = True,  # Return DRR with shape (b, 1, h, w)\n",
    "        reverse_x_axis: bool = False,  # If pose includes reflection (in E(3) not SE(3)), reverse x-axis\n",
    "        patch_size: int | None = None,  # Render patches of the DRR in series\n",
    "        bone_attenuation_multiplier: float = 1.0,  # Contrast ratio of bone to soft tissue\n",
    "        renderer: str = \"siddon\",  # Rendering backend, either \"siddon\" or \"trilinear\"\n",
    "        **renderer_kwargs,  # Kwargs for the renderer\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize the X-ray detector\n",
    "        width = height if width is None else width\n",
    "        dely = delx if dely is None else dely\n",
    "        n_subsample = (\n",
    "            int(height * width * p_subsample) if p_subsample is not None else None\n",
    "        )\n",
    "        self.detector = Detector(\n",
    "            sdr,\n",
    "            height,\n",
    "            width,\n",
    "            delx,\n",
    "            dely,\n",
    "            x0,\n",
    "            y0,\n",
    "            n_subsample=n_subsample,\n",
    "            reverse_x_axis=reverse_x_axis,\n",
    "        )\n",
    "\n",
    "        # Initialize the volume\n",
    "        self.register_buffer(\"spacing\", torch.tensor(spacing))\n",
    "        self.register_buffer(\"volume\", torch.tensor(volume).flip([0]))\n",
    "        self.reshape = reshape\n",
    "        self.patch_size = patch_size\n",
    "        if self.patch_size is not None:\n",
    "            self.n_patches = (height * width) // (self.patch_size**2)\n",
    "\n",
    "        # Parameters for segmenting the CT volume and reweighting voxels\n",
    "        self.air = torch.where(self.volume <= -800)\n",
    "        self.soft_tissue = torch.where((-800 < self.volume) & (self.volume <= 350))\n",
    "        self.bone = torch.where(350 < self.volume)\n",
    "        self.bone_attenuation_multiplier = bone_attenuation_multiplier\n",
    "\n",
    "        # Initialize the renderer\n",
    "        if renderer == \"siddon\":\n",
    "            self.renderer = Siddon(**renderer_kwargs)\n",
    "        elif renderer == \"trilinear\":\n",
    "            self.renderer = Trilinear(**renderer_kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"renderer must be 'siddon', not {renderer}\")\n",
    "\n",
    "    def reshape_transform(self, img, batch_size):\n",
    "        if self.reshape:\n",
    "            if self.detector.n_subsample is None:\n",
    "                img = img.view(-1, 1, self.detector.height, self.detector.width)\n",
    "            else:\n",
    "                img = reshape_subsampled_drr(img, self.detector, batch_size)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513c593-32b8-4676-83d4-e9e7dcf0630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def reshape_subsampled_drr(\n",
    "    img: torch.Tensor,\n",
    "    detector: Detector,\n",
    "    batch_size: int,\n",
    "):\n",
    "    n_points = detector.height * detector.width\n",
    "    drr = torch.zeros(batch_size, n_points).to(img)\n",
    "    drr[:, detector.subsamples[-1]] = img\n",
    "    drr = drr.view(batch_size, 1, detector.height, detector.width)\n",
    "    return drr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e203d-cc9e-414d-bd8e-a4053f858625",
   "metadata": {},
   "source": [
    "The forward pass of the `DRR` module generated DRRs from the input CT volume. The pose parameters (i.e., viewing angles) from which the DRRs are generated are passed to the forward call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b19dfc-6a15-4896-9faa-20faee84dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from diffdrr.pose import convert\n",
    "\n",
    "\n",
    "@patch\n",
    "def forward(\n",
    "    self: DRR,\n",
    "    *args,  # Some batched representation of SE(3)\n",
    "    parameterization: str = None,  # Specifies the representation of the rotation\n",
    "    convention: str = None,  # If parameterization is Euler angles, specify convention\n",
    "    bone_attenuation_multiplier: float = None,  # Contrast ratio of bone to soft tissue\n",
    "    **kwargs,  # Passed to the renderer\n",
    "):\n",
    "    \"\"\"Generate DRR with rotational and translational parameters.\"\"\"\n",
    "    if not hasattr(self, \"density\"):\n",
    "        self.set_bone_attenuation_multiplier(self.bone_attenuation_multiplier)\n",
    "    if bone_attenuation_multiplier is not None:\n",
    "        self.set_bone_attenuation_multiplier(bone_attenuation_multiplier)\n",
    "\n",
    "    if parameterization is None:\n",
    "        pose = args[0]\n",
    "    else:\n",
    "        pose = convert(*args, parameterization=parameterization, convention=convention)\n",
    "    source, target = self.detector(pose)\n",
    "\n",
    "    if self.patch_size is not None:\n",
    "        n_points = target.shape[1] // self.n_patches\n",
    "        img = []\n",
    "        for idx in range(self.n_patches):\n",
    "            t = target[:, idx * n_points : (idx + 1) * n_points]\n",
    "            partial = self.renderer(self.density, self.spacing, source, t, **kwargs)\n",
    "            img.append(partial)\n",
    "        img = torch.cat(img, dim=1)\n",
    "    else:\n",
    "        img = self.renderer(self.density, self.spacing, source, target, **kwargs)\n",
    "    return self.reshape_transform(img, batch_size=len(pose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0cfccb-f305-4a4f-a8f2-bb9fccc19798",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@patch\n",
    "def set_bone_attenuation_multiplier(self: DRR, bone_attenuation_multiplier: float):\n",
    "    self.density = torch.empty_like(self.volume)\n",
    "    self.density[self.air] = self.volume[self.soft_tissue].min()\n",
    "    self.density[self.soft_tissue] = self.volume[self.soft_tissue]\n",
    "    self.density[self.bone] = self.volume[self.bone] * bone_attenuation_multiplier\n",
    "    self.density -= self.density.min()\n",
    "    self.density /= self.density.max()\n",
    "    self.bone_attenuation_multiplier = bone_attenuation_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17edb1b-d3b4-4f31-b110-f5811ec6c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@patch\n",
    "def set_intrinsics(\n",
    "    self: DRR,\n",
    "    sdr: float = None,\n",
    "    delx: float = None,\n",
    "    dely: float = None,\n",
    "    x0: float = None,\n",
    "    y0: float = None,\n",
    "):\n",
    "    self.detector = Detector(\n",
    "        sdr if sdr is not None else self.detector.sdr,\n",
    "        self.detector.height,\n",
    "        self.detector.width,\n",
    "        delx if delx is not None else self.detector.delx,\n",
    "        dely if dely is not None else self.detector.dely,\n",
    "        x0 if x0 is not None else self.detector.x0,\n",
    "        y0 if y0 is not None else self.detector.y0,\n",
    "        n_subsample=self.detector.n_subsample,\n",
    "        reverse_x_axis=self.detector.reverse_x_axis,\n",
    "    ).to(self.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a94ef3-5449-45dc-aa62-9fcf6fad643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from diffdrr.pose import RigidTransform\n",
    "\n",
    "\n",
    "@patch\n",
    "def perspective_projection(\n",
    "    self: DRR,\n",
    "    pose: RigidTransform,\n",
    "    pts: torch.Tensor,\n",
    "):\n",
    "    extrinsic = (\n",
    "        pose.inverse().compose(self.detector.translate).compose(self.detector.flip_xz)\n",
    "    )\n",
    "    x = extrinsic(pts)\n",
    "    x = torch.einsum(\"ij, bnj -> bni\", self.detector.intrinsic, x)\n",
    "    z = x[..., -1].unsqueeze(-1).clone()\n",
    "    x = x / z\n",
    "    return x[..., :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ba874-eef8-4524-be5c-bd250e5639d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "\n",
    "@patch\n",
    "def inverse_projection(\n",
    "    self: DRR,\n",
    "    pose: RigidTransform,\n",
    "    pts: torch.Tensor,\n",
    "):\n",
    "    extrinsic = (\n",
    "        self.detector.flip_xz.inverse()\n",
    "        .compose(self.detector.translate.inverse())\n",
    "        .compose(pose)\n",
    "    )\n",
    "    x = (\n",
    "        -2\n",
    "        * self.detector.sdr\n",
    "        * torch.einsum(\n",
    "            \"ij, bnj -> bni\",\n",
    "            self.detector.intrinsic.inverse(),\n",
    "            pad(pts, (0, 1), value=1),  # Convert to homogenous coordinates\n",
    "        )\n",
    "    )\n",
    "    return extrinsic(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc1b2b-a444-45dc-8430-56646d54f95f",
   "metadata": {},
   "source": [
    "## Registration\n",
    "\n",
    "The `Registration` module uses the `DRR` module to perform differentiable 2D-to-3D registration. Initial guesses for the pose parameters are as stored as `nn.Parameters` of the module. This allows the pose parameters to be optimized with any PyTorch optimizer. Furthermore, this design choice allows `DRR` to be used purely as a differentiable renderer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868fd7b9-e83d-43dd-89e2-3d49e0434da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Registration(nn.Module):\n",
    "    \"\"\"Perform automatic 2D-to-3D registration using differentiable rendering.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        drr: DRR,\n",
    "        rotation: torch.Tensor,\n",
    "        translation: torch.Tensor,\n",
    "        parameterization: str,\n",
    "        convention: str = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.drr = drr\n",
    "        self.rotation = nn.Parameter(rotation)\n",
    "        self.translation = nn.Parameter(translation)\n",
    "        self.parameterization = parameterization\n",
    "        self.convention = convention\n",
    "\n",
    "    def forward(self):\n",
    "        return self.drr(\n",
    "            self.rotation,\n",
    "            self.translation,\n",
    "            parameterization=self.parameterization,\n",
    "            convention=self.convention,\n",
    "        )\n",
    "\n",
    "    def get_rotation(self):\n",
    "        return self.rotation.clone().detach().cpu()\n",
    "\n",
    "    def get_translation(self):\n",
    "        return self.translation.clone().detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95beb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a9e0b-0daf-4f74-b1e1-3f79fb52ae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
