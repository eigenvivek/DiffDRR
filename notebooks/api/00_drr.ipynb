{
 "cells": [
  {
   "cell_type": "raw",
   "id": "12e70d79",
   "metadata": {},
   "source": [
    "---\n",
    "title: DRR\n",
    "description: Module for computing digitally reconstructed radiographs\n",
    "output-file: drr.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fcd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp drr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5be32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95e1ac-413e-407b-87ad-0c7db3a945de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from fastcore.basics import patch\n",
    "\n",
    "from diffdrr.detector import Detector\n",
    "from diffdrr.renderers import Siddon, Trilinear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd42817-b14a-42a4-bf73-c7ea4da2890c",
   "metadata": {},
   "source": [
    "## DRR\n",
    "`DRR` is a PyTorch module that compues differentiable digitally reconstructed radiographs. The viewing angle for the DRR (known generally in computer graphics as the *camera pose*) is parameterized by the following parameters:\n",
    "\n",
    "- SDD : source-to-detector distance (i.e., the focal length of the C-arm)\n",
    "- $\\mathbf R \\in \\mathrm{SO}(3)$ : a rotation\n",
    "- $\\mathbf t \\in \\mathbb R^3$ : a translation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a266460-9b18-4f8a-9bee-d78834b4ff0d",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "`DiffDRR` can take a rotation parameterized in any of the following forms to move the detector plane:\n",
    "\n",
    "- `axis_angle`\n",
    "- `euler_angles` (note: also need to specify the `convention` for the Euler angles)\n",
    "- `matrix`\n",
    "- `quaternion` \n",
    "- `quaternion_adjugate` ([Hanson and Hanson, 2022](https://arxiv.org/abs/2205.09116))\n",
    "- `rotation_6d` ([Zhou et al., 2019](https://arxiv.org/abs/1812.07035))\n",
    "- `rotation_10d` ([Peretroukhin et al., 2021](https://arxiv.org/abs/2006.01031))`\n",
    "- `se3_log_map`\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cc09da-a788-4d2d-a780-c84a1e9c6bb6",
   "metadata": {},
   "source": [
    "If using Euler angles, the parameters are\n",
    "\n",
    "- `alpha`      : Azimuthal angle\n",
    "- `beta`       : Polar angle\n",
    "- `gamma`      : Plane rotation angle\n",
    "- `bx`         : X-dir translation\n",
    "- `by`         : Y-dir translation\n",
    "- `bz`         : Z-dir translation\n",
    "- `convention` : Order of angles (e.g., `ZYX`)\n",
    "\n",
    "`(bx, by, bz)` are translational parameters and `(alpha, beta, gamma)` are rotational parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97297d06-6772-4dc7-8af5-d1ea7b379d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torchio import Subject\n",
    "\n",
    "from diffdrr.pose import RigidTransform\n",
    "\n",
    "\n",
    "class DRR(nn.Module):\n",
    "    \"\"\"PyTorch module that computes differentiable digitally reconstructed radiographs.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        subject: Subject,  # TorchIO wrapper for the CT volume\n",
    "        sdd: float,  # Source-to-detector distance (i.e., the C-arm's focal length)\n",
    "        height: int,  # Height of the rendered DRR\n",
    "        delx: float,  # X-axis pixel size\n",
    "        width: int | None = None,  # Width of the rendered DRR (default to `height`)\n",
    "        dely: float | None = None,  # Y-axis pixel size (if not provided, set to `delx`)\n",
    "        x0: float = 0.0,  # Principal point X-offset\n",
    "        y0: float = 0.0,  # Principal point Y-offset\n",
    "        p_subsample: float | None = None,  # Proportion of pixels to randomly subsample\n",
    "        reshape: bool = True,  # Return DRR with shape (b, 1, h, w)\n",
    "        reverse_x_axis: bool = True,  # If True, obey radiologic convention (e.g., heart on right)\n",
    "        patch_size: int | None = None,  # Render patches of the DRR in series\n",
    "        renderer: str = \"siddon\",  # Rendering backend, either \"siddon\" or \"trilinear\"\n",
    "        persistent: bool = True,  # Set persistent value in `torch.nn.Module.register_buffer`\n",
    "        **renderer_kwargs,  # Kwargs for the renderer\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize the X-ray detector\n",
    "        width = height if width is None else width\n",
    "        dely = delx if dely is None else dely\n",
    "        if p_subsample is not None:\n",
    "            n_subsample = int(height * width * p_subsample)\n",
    "        else:\n",
    "            n_subsample = None\n",
    "        self.detector = Detector(\n",
    "            sdd,\n",
    "            height,\n",
    "            width,\n",
    "            delx,\n",
    "            dely,\n",
    "            x0,\n",
    "            y0,\n",
    "            subject.reorient,\n",
    "            reverse_x_axis=reverse_x_axis,\n",
    "            n_subsample=n_subsample,\n",
    "        )\n",
    "\n",
    "        # Initialize the volume and world geometry\n",
    "        self.subject = subject\n",
    "        self.volume = subject.volume.data.squeeze()\n",
    "        self.register_buffer(\n",
    "            \"density\",\n",
    "            subject.density.data.squeeze(),\n",
    "            persistent=persistent,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"_affine\",\n",
    "            torch.as_tensor(subject.volume.affine, dtype=torch.float32).unsqueeze(0),\n",
    "            persistent=persistent,\n",
    "        )  # Using float64 can sometimes improve rendering quality (https://github.com/eigenvivek/DiffDRR/issues/202)\n",
    "        self.register_buffer(\n",
    "            \"_affine_inverse\",\n",
    "            self._affine.inverse(),\n",
    "            persistent=persistent,\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"density\",\n",
    "            subject.density.data.squeeze(),\n",
    "            persistent=persistent,\n",
    "        )\n",
    "        if subject.mask is not None:\n",
    "            self.register_buffer(\n",
    "                \"mask\",\n",
    "                subject.mask.data.to(torch.float32).squeeze(),\n",
    "                persistent=persistent,\n",
    "            )\n",
    "\n",
    "        # Initialize the renderer\n",
    "        if renderer == \"siddon\":\n",
    "            self.renderer = Siddon(**renderer_kwargs)\n",
    "        elif renderer == \"trilinear\":\n",
    "            self.renderer = Trilinear(**renderer_kwargs)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"renderer must be 'siddon' or 'trilinear', not {renderer}\"\n",
    "            )\n",
    "        self.reshape = reshape\n",
    "        self.patch_size = patch_size\n",
    "        if self.patch_size is not None:\n",
    "            self.n_patches = (height * width) // (self.patch_size**2)\n",
    "\n",
    "    def reshape_transform(self, img, batch_size):\n",
    "        if self.reshape:\n",
    "            if self.detector.n_subsample is None:\n",
    "                img = img.view(\n",
    "                    batch_size, -1, self.detector.height, self.detector.width\n",
    "                )\n",
    "            else:\n",
    "                img = reshape_subsampled_drr(img, self.detector, batch_size)\n",
    "        return img\n",
    "\n",
    "    @property\n",
    "    def affine(self):\n",
    "        return RigidTransform(self._affine)\n",
    "\n",
    "    @property\n",
    "    def affine_inverse(self):\n",
    "        return RigidTransform(self._affine_inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6513c593-32b8-4676-83d4-e9e7dcf0630a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def reshape_subsampled_drr(img: torch.Tensor, detector: Detector, batch_size: int):\n",
    "    n_points = detector.height * detector.width\n",
    "    drr = torch.zeros(batch_size, n_points).to(img)\n",
    "    drr[:, detector.subsamples[-1]] = img\n",
    "    drr = drr.view(batch_size, 1, detector.height, detector.width)\n",
    "    return drr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99e203d-cc9e-414d-bd8e-a4053f858625",
   "metadata": {},
   "source": [
    "The forward pass of the `DRR` module generated DRRs from the input CT volume. The pose parameters (i.e., viewing angles) from which the DRRs are generated are passed to the forward call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b19dfc-6a15-4896-9faa-20faee84dc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from diffdrr.pose import RigidTransform, convert\n",
    "\n",
    "\n",
    "@patch\n",
    "def forward(\n",
    "    self: DRR,\n",
    "    *args,  # Some batched representation of SE(3)\n",
    "    parameterization: str = None,  # Specifies the representation of the rotation\n",
    "    convention: str = None,  # If parameterization is Euler angles, specify convention\n",
    "    calibration: RigidTransform = None,  # Optional calibration matrix with the detector's intrinsic parameters\n",
    "    mask_to_channels: bool = False,  # If True, structures from the CT mask are rendered in separate channels\n",
    "    **kwargs,  # Passed to the renderer\n",
    "):\n",
    "    \"\"\"Generate DRR with rotational and translational parameters.\"\"\"\n",
    "    # Initialize the camera pose\n",
    "    if parameterization is None:\n",
    "        pose = args[0]\n",
    "    else:\n",
    "        pose = convert(*args, parameterization=parameterization, convention=convention)\n",
    "    source, target = self.detector(pose, calibration)\n",
    "    source = self.affine_inverse(source)\n",
    "    target = self.affine_inverse(target)\n",
    "\n",
    "    # Render the DRR\n",
    "    kwargs[\"mask\"] = self.mask if mask_to_channels else None\n",
    "    if self.patch_size is None:\n",
    "        img = self.renderer(\n",
    "            self.density,\n",
    "            source,\n",
    "            target,\n",
    "            **kwargs,\n",
    "        )\n",
    "    else:\n",
    "        n_points = target.shape[1] // self.n_patches\n",
    "        img = []\n",
    "        for idx in range(self.n_patches):\n",
    "            t = target[:, idx * n_points : (idx + 1) * n_points]\n",
    "            partial = self.renderer(\n",
    "                self.density,\n",
    "                source,\n",
    "                t,\n",
    "                **kwargs,\n",
    "            )\n",
    "            img.append(partial)\n",
    "        img = torch.cat(img, dim=-1)\n",
    "    return self.reshape_transform(img, batch_size=len(pose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17edb1b-d3b4-4f31-b110-f5811ec6c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@patch\n",
    "def set_intrinsics(\n",
    "    self: DRR,\n",
    "    sdd: float = None,\n",
    "    delx: float = None,\n",
    "    dely: float = None,\n",
    "    x0: float = None,\n",
    "    y0: float = None,\n",
    "):\n",
    "    self.detector = Detector(\n",
    "        sdd if sdd is not None else self.detector.sdd,\n",
    "        self.detector.height,\n",
    "        self.detector.width,\n",
    "        delx if delx is not None else self.detector.delx,\n",
    "        dely if dely is not None else self.detector.dely,\n",
    "        x0 if x0 is not None else self.detector.x0,\n",
    "        y0 if y0 is not None else self.detector.y0,\n",
    "        n_subsample=self.detector.n_subsample,\n",
    "        reverse_x_axis=self.detector.reverse_x_axis,\n",
    "        reorient=self.subject.reorient,\n",
    "    ).to(self.volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a94ef3-5449-45dc-aa62-9fcf6fad643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def perspective_projection(\n",
    "    self: DRR,\n",
    "    pose: RigidTransform,\n",
    "    pts: torch.Tensor,\n",
    "):\n",
    "    \"\"\"Project points in world coordinates (3D) onto the pixel plane (2D).\"\"\"\n",
    "    extrinsic = (self.detector.reorient.compose(pose)).inverse()\n",
    "    x = extrinsic(pts)\n",
    "    x = torch.einsum(\"ij, bnj -> bni\", self.detector.intrinsic, x)\n",
    "    z = x[..., -1].unsqueeze(-1).clone()\n",
    "    x = x / z\n",
    "    if self.detector.reverse_x_axis:\n",
    "        x[..., 1] = self.detector.width - x[..., 1]\n",
    "    return x[..., :2].flip(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802ba874-eef8-4524-be5c-bd250e5639d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "\n",
    "@patch\n",
    "def inverse_projection(\n",
    "    self: DRR,\n",
    "    pose: RigidTransform,\n",
    "    pts: torch.Tensor,\n",
    "):\n",
    "    \"\"\"Backproject points in pixel plane (2D) onto the image plane in world coordinates (3D).\"\"\"\n",
    "    pts = pts.flip(-1)\n",
    "    if self.detector.reverse_x_axis:\n",
    "        pts[..., 1] = self.detector.width - pts[..., 1]\n",
    "    x = self.detector.sdd * torch.einsum(\n",
    "        \"ij, bnj -> bni\",\n",
    "        self.detector.intrinsic.inverse(),\n",
    "        pad(pts, (0, 1), value=1),  # Convert to homogenous coordinates\n",
    "    )\n",
    "    extrinsic = self.detector.reorient.compose(pose)\n",
    "    return extrinsic(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95beb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a9e0b-0daf-4f74-b1e1-3f79fb52ae6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
