{
 "cells": [
  {
   "cell_type": "raw",
   "id": "f53988ba",
   "metadata": {},
   "source": [
    "---\n",
    "title: visualization\n",
    "description: Visualize and animate DRRs in 2D and 3D\n",
    "output-file: visualization.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18064199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eedf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34c0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import tempfile\n",
    "\n",
    "import imageio.v3 as iio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101fb02-aa5f-476c-bf49-c9750b181e89",
   "metadata": {},
   "source": [
    "## 2D Visualization\n",
    "\n",
    "Uses `matplotlib` and `imageio` to plot DRRs and animate optimization over DRRs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbd598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "\n",
    "\n",
    "def plot_drr(\n",
    "    img: torch.Tensor,\n",
    "    title: str | None = None,\n",
    "    ticks: bool | None = True,\n",
    "    axs: matplotlib.axes._axes.Axes | None = None,\n",
    "):\n",
    "    \"\"\"Plot an image generated by a DRR module.\"\"\"\n",
    "\n",
    "    if axs is None:\n",
    "        fig, axs = plt.subplots(ncols=len(img), figsize=(10, 5))\n",
    "    if len(img) == 1:\n",
    "        axs = [axs]\n",
    "    for img, ax in zip(img, axs):\n",
    "        ax.imshow(img.squeeze().cpu().detach(), cmap=\"gray\")\n",
    "        _, height, width = img.shape\n",
    "        ax.xaxis.tick_top()\n",
    "        ax.set(\n",
    "            title=title,\n",
    "            xticks=[0, width - 1],\n",
    "            xticklabels=[1, width],\n",
    "            yticks=[0, height - 1],\n",
    "            yticklabels=[1, height],\n",
    "        )\n",
    "        if ticks is False:\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1931b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pathlib\n",
    "\n",
    "import pandas\n",
    "\n",
    "from diffdrr.drr import DRR\n",
    "\n",
    "\n",
    "def animate(\n",
    "    out: str | pathlib.Path,  # Savepath\n",
    "    df: pandas.DataFrame,\n",
    "    drr: DRR,\n",
    "    parameterization: str,\n",
    "    convention: str = None,\n",
    "    ground_truth: torch.Tensor | None = None,\n",
    "    verbose: bool = True,\n",
    "    device=\"cpu\",\n",
    "    **kwargs,  # To pass to imageio.v3.imwrite\n",
    "):\n",
    "    \"\"\"Animate the optimization of a DRR.\"\"\"\n",
    "    # Make the axes\n",
    "    if ground_truth is None:\n",
    "\n",
    "        def make_fig():\n",
    "            fig, ax_opt = plt.subplots(\n",
    "                figsize=(3, 3),\n",
    "                constrained_layout=True,\n",
    "            )\n",
    "            return fig, ax_opt\n",
    "\n",
    "    else:\n",
    "\n",
    "        def make_fig(ground_truth):\n",
    "            fig, (ax_fix, ax_opt) = plt.subplots(\n",
    "                ncols=2,\n",
    "                figsize=(6, 3),\n",
    "                constrained_layout=True,\n",
    "            )\n",
    "            plot_drr(ground_truth, axs=ax_fix)\n",
    "            ax_fix.set(xlabel=\"Fixed DRR\")\n",
    "            return fig, ax_opt\n",
    "\n",
    "    # Compute DRRs, plot, and save to temporary folder\n",
    "    if verbose:\n",
    "        itr = tqdm(df.iterrows(), desc=\"Precomputing DRRs\", total=len(df), ncols=75)\n",
    "    else:\n",
    "        itr = df.iterrows()\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        idxs = []\n",
    "        for idx, row in itr:\n",
    "            fig, ax_opt = make_fig() if ground_truth is None else make_fig(ground_truth)\n",
    "            params = row[[\"alpha\", \"beta\", \"gamma\", \"bx\", \"by\", \"bz\"]].values\n",
    "            rotations = (\n",
    "                torch.tensor(row[[\"alpha\", \"beta\", \"gamma\"]].values)\n",
    "                .unsqueeze(0)\n",
    "                .to(device)\n",
    "            )\n",
    "            translations = (\n",
    "                torch.tensor(row[[\"bx\", \"by\", \"bz\"]].values).unsqueeze(0).to(device)\n",
    "            )\n",
    "            itr = drr(rotations, translations, parameterization, convention)\n",
    "            _ = plot_drr(itr, axs=ax_opt)\n",
    "            ax_opt.set(xlabel=f\"Moving DRR (loss = {row['loss']:.3f})\")\n",
    "            fig.savefig(f\"{tmpdir}/{idx}.png\")\n",
    "            plt.close(fig)\n",
    "            idxs.append(idx)\n",
    "        frames = np.stack(\n",
    "            [iio.imread(f\"{tmpdir}/{idx}.png\") for idx in idxs],\n",
    "            axis=0,\n",
    "        )\n",
    "\n",
    "    # Make the animation\n",
    "    return iio.imwrite(out, frames, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cccffa4-7d85-44ab-b620-5f584718ebed",
   "metadata": {},
   "source": [
    "`df` is a `pandas.DataFrame` with columns `[\"alpha\", \"beta\", \"gamma\", \"bx\", \"by\", \"bz\"]`. Each row in `df` is an iteration of optimization with the updated values for that timestep."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf37a20-22a5-4b31-9411-4ad1998ca345",
   "metadata": {},
   "source": [
    "## 3D Visualization\n",
    "\n",
    "Uses `pyvista` and `trame` to interactively visualize DRR geometry in 3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6718de4-26c6-4550-9d88-780fa5b809f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pyvista\n",
    "\n",
    "from diffdrr.drr import DRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bce480-3f93-49ba-bdd5-8677ac1e8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def drr_to_mesh(\n",
    "    drr: DRR,\n",
    "    threshold: float = 300,  # Min value for marching cubes (Hounsfield units)\n",
    "    verbose: bool = True,  # Display progress bars for mesh processing steps\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert the CT in a DRR object into a mesh.\n",
    "\n",
    "    Mesh processing steps:\n",
    "\n",
    "    1. Keep only largest connected components\n",
    "    2. Smooth\n",
    "    3. Decimate\n",
    "    4. Fill any holes\n",
    "    5. Clean (remove any redundant vertices/edges)\n",
    "    \"\"\"\n",
    "    # Turn the CT into a PyVista object and run marching cubes\n",
    "    grid = pyvista.ImageData(\n",
    "        dimensions=drr.volume.shape,\n",
    "        spacing=drr.spacing,\n",
    "        origin=(0, 0, 0),\n",
    "    )\n",
    "    mesh = grid.contour(\n",
    "        isosurfaces=1,\n",
    "        scalars=drr.volume.cpu().numpy().flatten(order=\"F\"),\n",
    "        rng=[threshold, torch.inf],\n",
    "        method=\"marching_cubes\",\n",
    "        progress_bar=verbose,\n",
    "    )\n",
    "\n",
    "    # Process the mesh\n",
    "    mesh.extract_largest(inplace=True, progress_bar=verbose)\n",
    "    mesh.point_data.clear()\n",
    "    mesh.cell_data.clear()\n",
    "    mesh.smooth_taubin(\n",
    "        n_iter=100,\n",
    "        feature_angle=120.0,\n",
    "        boundary_smoothing=False,\n",
    "        feature_smoothing=False,\n",
    "        non_manifold_smoothing=True,\n",
    "        normalize_coordinates=True,\n",
    "        inplace=True,\n",
    "        progress_bar=verbose,\n",
    "    )\n",
    "    mesh.decimate_pro(0.25, inplace=True, progress_bar=verbose)\n",
    "    mesh.fill_holes(100, inplace=True, progress_bar=verbose)\n",
    "    mesh.clean(inplace=True, progress_bar=verbose)\n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bec80c-947e-4b66-8205-c540a1342f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def img_to_mesh(drr: DRR, rotations, translations, parameterization, convention=None):\n",
    "    \"\"\"\n",
    "    For a given pose (not batched), turn the camera and detector into a mesh.\n",
    "    Additionally, render the DRR for the pose. Convert into a texture that\n",
    "    can be applied to the detector mesh.\n",
    "    \"\"\"\n",
    "    # Turn DRR img into a texture that can be applied to a mesh\n",
    "    img = drr(rotations, translations, parameterization, convention)\n",
    "    img = img.detach().cpu().squeeze().numpy()\n",
    "    img = (img - img.min()) / (img.max() - img.min())\n",
    "    img = (255.0 * img).astype(np.uint8)\n",
    "    texture = pyvista.numpy_to_texture(img)\n",
    "\n",
    "    # Make a mesh for the source and detector plane\n",
    "    source, target = drr.detector(rotations, translations, parameterization, convention)\n",
    "    camera = pyvista.Sphere(radius=10, center=source.squeeze().cpu().numpy())\n",
    "    target = target.reshape(drr.detector.height, drr.detector.width, 3).cpu().numpy()\n",
    "    detector = pyvista.StructuredGrid(\n",
    "        target[..., 0],\n",
    "        target[..., 1],\n",
    "        target[..., 2],\n",
    "    )\n",
    "    detector.add_field_data([drr.detector.height], \"height\")\n",
    "    detector.add_field_data([drr.detector.width], \"width\")\n",
    "    detector.texture_map_to_plane(\n",
    "        origin=target[-1, 0],\n",
    "        point_u=target[-1, -1],\n",
    "        point_v=target[0, 0],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    return camera, detector, texture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e392aed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253e372-c4da-416d-ad50-c561369ca9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
