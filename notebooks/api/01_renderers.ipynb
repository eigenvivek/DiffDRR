{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: renderers\n",
    "description: Mapping rays to pixel intensities\n",
    "output-file: renderers.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp renderers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siddon's Method\n",
    "\n",
    "DRRs are generated by modeling the geometry of an idealized projectional radiography system.\n",
    "Let $\\mathbf s \\in \\mathbb R^3$ be the X-ray source and $\\mathbf p \\in \\mathbb R^3$ be a target pixel on the detector plane.\n",
    "Then, $R(\\alpha) = \\mathbf s + \\alpha (\\mathbf p - \\mathbf s)$ is a ray that originates from $\\mathbf s$ ($\\alpha=0$), passes through the imaged volume, and hits the detector plane at $\\mathbf p$ ($\\alpha=1$).\n",
    "The proportion of energy attenuation experienced by the X-ray at the time it reaches pixel $\\mathbf p$ is given by the following line integral:\n",
    "\n",
    "\\begin{equation}\n",
    "    E(R) = \\|\\mathbf p - \\mathbf s\\|_2 \\int_0^1 \\mathbf V \\left( \\mathbf s + \\alpha (\\mathbf p - \\mathbf s) \\right) \\, \\mathrm d\\alpha \\,,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf V : \\mathbb R^3 \\mapsto \\mathbb R$ is the imaged volume.\n",
    "The units term $\\|\\mathbf p - \\mathbf s\\|_2$ serves to cancel out the units of $\\mathbf V(\\cdot)$, reciprocal length, such that the final proportion $E$ is unitless.\n",
    "For DRR synthesis, $\\mathbf V$ is approximated by a discrete 3D CT volume, and the first equation becomes\n",
    "\n",
    "\\begin{equation}\n",
    "    E(R) = \\|\\mathbf p - \\mathbf s\\|_2 \\sum_{m=1}^{M-1} (\\alpha_{m+1} - \\alpha_m) \\mathbf V \\left[ \\mathbf s + \\frac{\\alpha_{m+1} + \\alpha_m}{2} (\\mathbf p - \\mathbf s) \\right] \\,,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\alpha_m$ parameterizes the locations where ray $R$ intersects one of the orthogonal planes comprising the CT volume, and $M$ is the number of such intersections."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Note that this model does not account for patterns of reflection and scattering that are present in real X-ray systems.\n",
    "While these simplifications preclude synthesis of realistic X-rays, the model in Siddon's method has been widely and successfully used in slice-to-volume registration.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siddon's method provides a parametric method to identify the plane intersections $\\{\\alpha_m\\}_{m=1}^M$.\n",
    "Let $\\Delta X$ be the CT voxel size in the $x$-direction and $b_x$ be the location of the $0$-th plane in this direction.\n",
    "Then the intersection of ray $R$ with the $i$-th plane in the $x$-direction is given by\n",
    "\\begin{equation}\n",
    "    \\alpha_x(i) = \\frac{b_x + i \\Delta X - \\mathbf s_x}{\\mathbf p_x - \\mathbf s_x} ,\n",
    "\\end{equation}\n",
    "with analogous expressions for $\\alpha_y(\\cdot)$ and $\\alpha_z(\\cdot)$.\n",
    "\n",
    "We can use this equation to compute the values $\\mathbf \\alpha_x$ for all the intersections between $R$ and the planes in the $x$-direction:\n",
    "\\begin{equation}\n",
    "    \\mathbf\\alpha_x = \\{ \\alpha_x(i_{\\min}), \\dots, \\alpha_x(i_{\\max}) \\} ,\n",
    "\\end{equation}\n",
    "where $i_{\\min}$ and $i_{\\max}$ denote the first and last intersections of $R$ with the $x$-direction planes.\n",
    "\n",
    "Defining $\\mathbf\\alpha_y$ and $\\mathbf\\alpha_z$ analogously, we construct the array\n",
    "\\begin{equation}\n",
    "    \\mathbf\\alpha = \\mathrm{sort}(\\mathbf\\alpha_x, \\mathbf\\alpha_y, \\mathbf\\alpha_z) ,\n",
    "\\end{equation}\n",
    "which contains $M$ values of $\\alpha$ parameterizing the intersections between $R$ and the orthogonal $x$-, $y$-, and $z$-directional planes. \n",
    "We substitute values in the sorted set $\\mathbf\\alpha$ into the first equation to evaluate $E(R)$, which corresponds to the intensity of pixel $\\mathbf p$ in the synthesized DRR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Siddon(torch.nn.Module):\n",
    "    \"\"\"Differentiable X-ray renderer implemented with Siddon's method for exact raytracing.\"\"\"\n",
    "\n",
    "    def __init__(self, eps=1e-8):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def dims(self, volume):\n",
    "        return torch.tensor(volume.shape).to(volume) + 1\n",
    "\n",
    "    def maxidx(self, volume):\n",
    "        return volume.numel() - 1\n",
    "\n",
    "    def forward(self, volume, origin, spacing, source, target, mask=None):\n",
    "        dims = self.dims(volume)\n",
    "        maxidx = self.maxidx(volume)\n",
    "        origin = origin.to(torch.float64)\n",
    "\n",
    "        alphas = _get_alphas(source, target, origin, spacing, dims, self.eps)\n",
    "        alphamid = (alphas[..., 0:-1] + alphas[..., 1:]) / 2\n",
    "        voxels, idxs = _get_voxel(\n",
    "            alphamid, source, target, volume, origin, spacing, dims, maxidx, self.eps\n",
    "        )\n",
    "\n",
    "        # Step length for alphas out of range will be nan\n",
    "        # These nans cancel out voxels convereted to 0 index\n",
    "        step_length = torch.diff(alphas, dim=-1)\n",
    "        weighted_voxels = voxels * step_length\n",
    "\n",
    "        # Handle optional masking\n",
    "        if mask is None:\n",
    "            img = torch.nansum(weighted_voxels, dim=-1)\n",
    "            img = img.unsqueeze(1)\n",
    "        else:\n",
    "            # Thanks to @Ivan for the clutch assist w/ pytorch tensor ops\n",
    "            # https://stackoverflow.com/questions/78323859/broadcast-pytorch-array-across-channels-based-on-another-array/78324614#78324614\n",
    "            channels = torch.take(mask, idxs)  # B D N\n",
    "            weighted_voxels = weighted_voxels.nan_to_num()\n",
    "            B, D, N = weighted_voxels.shape\n",
    "            C = mask.max().item() + 1\n",
    "            img = (\n",
    "                torch.zeros(B, C, D)\n",
    "                .to(volume)\n",
    "                .scatter_add_(\n",
    "                    1, channels.transpose(-1, -2), weighted_voxels.transpose(-1, -2)\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # Finish rendering the DRR\n",
    "        raylength = (target - source + self.eps).norm(dim=-1)\n",
    "        img *= raylength.unsqueeze(1)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_alphas(source, target, origin, spacing, dims, eps):\n",
    "    # Get the CT sizing and spacing parameters\n",
    "    alphax = torch.arange(dims[0]).to(source) * spacing[0] + origin[0]\n",
    "    alphay = torch.arange(dims[1]).to(source) * spacing[1] + origin[1]\n",
    "    alphaz = torch.arange(dims[2]).to(source) * spacing[2] + origin[2]\n",
    "\n",
    "    # Get the alpha at each plane intersection\n",
    "    sx, sy, sz = source[..., 0], source[..., 1], source[..., 2]\n",
    "    alphax = alphax.expand(len(source), 1, -1) - sx.unsqueeze(-1)\n",
    "    alphay = alphay.expand(len(source), 1, -1) - sy.unsqueeze(-1)\n",
    "    alphaz = alphaz.expand(len(source), 1, -1) - sz.unsqueeze(-1)\n",
    "\n",
    "    sdd = target - source + eps\n",
    "    alphax = alphax / sdd[..., 0].unsqueeze(-1)\n",
    "    alphay = alphay / sdd[..., 1].unsqueeze(-1)\n",
    "    alphaz = alphaz / sdd[..., 2].unsqueeze(-1)\n",
    "    alphas = torch.cat([alphax, alphay, alphaz], dim=-1)\n",
    "\n",
    "    # Get the alphas within the range [alphamin, alphamax]\n",
    "    alphamin, alphamax = _get_alpha_minmax(sdd, source, target, origin, spacing, dims)\n",
    "    good_idxs = torch.logical_and(alphas >= alphamin, alphas <= alphamax)\n",
    "    alphas[~good_idxs] = torch.nan\n",
    "\n",
    "    # Sort the alphas by ray, putting nans at the end of the list\n",
    "    alphas = torch.sort(alphas, dim=-1).values\n",
    "\n",
    "    # Drop indices where alphas for all rays are nan\n",
    "    alphas = alphas[..., ~alphas.isnan().all(dim=0).all(dim=0)]\n",
    "\n",
    "    return alphas\n",
    "\n",
    "\n",
    "def _get_alpha_minmax(sdd, source, target, origin, spacing, dims):\n",
    "    planes = torch.zeros(3).to(source)\n",
    "    alpha0 = (planes * spacing + origin - source) / sdd\n",
    "    planes = (dims - 1).to(source)\n",
    "    alpha1 = (planes * spacing + origin - source) / sdd\n",
    "    alphas = torch.stack([alpha0, alpha1]).to(source)\n",
    "\n",
    "    alphamin = alphas.min(dim=0).values.max(dim=-1).values.unsqueeze(-1)\n",
    "    alphamax = alphas.max(dim=0).values.min(dim=-1).values.unsqueeze(-1)\n",
    "\n",
    "    alphamin = torch.where(alphamin < 0.0, 0.0, alphamin)\n",
    "    alphamax = torch.where(alphamax > 1.0, 1.0, alphamax)\n",
    "    return alphamin, alphamax\n",
    "\n",
    "\n",
    "def _get_voxel(alpha, source, target, volume, origin, spacing, dims, maxidx, eps):\n",
    "    idxs = _get_index(alpha, source, target, origin, spacing, dims, maxidx, eps)\n",
    "    return torch.take(volume, idxs), idxs\n",
    "\n",
    "\n",
    "def _get_index(alpha, source, target, origin, spacing, dims, maxidx, eps):\n",
    "    sdd = target - source + eps\n",
    "    idxs = source.unsqueeze(2) + alpha.unsqueeze(-1) * sdd.unsqueeze(2)\n",
    "    idxs = (idxs - origin) / spacing\n",
    "    idxs = idxs.floor()\n",
    "    # Conversion to long makes nan->-inf, so temporarily replace them with 0\n",
    "    # This is cancelled out later by multiplication by nan step_length\n",
    "    idxs = (\n",
    "        idxs[..., 0] * (dims[1] - 1) * (dims[2] - 1)\n",
    "        + idxs[..., 1] * (dims[2] - 1)\n",
    "        + idxs[..., 2]\n",
    "    ).long()\n",
    "    idxs[idxs < 0] = 0\n",
    "    idxs[idxs > maxidx] = maxidx\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trilinear interpolation\n",
    "\n",
    "Instead of computing the exact line integral over the voxel grid (i.e., Siddon's method), we can sample colors at points along the each ray using trilinear interpolation.\n",
    "\n",
    "Now, the rendering equation is\n",
    "\\begin{equation}\n",
    "    E(R) = \\|\\mathbf p - \\mathbf s\\|_2\\frac{1}{M} \\sum_{m=1}^{M} \\mathbf V \\left[ \\mathbf s + \\alpha_m (\\mathbf p - \\mathbf s) \\right] \\,,\n",
    "\\end{equation}\n",
    "where $\\mathbf V[\\cdot]$ is the trilinear interpolation function and $M$ is the number of points sampled per ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch.nn.functional import grid_sample\n",
    "\n",
    "\n",
    "class Trilinear(torch.nn.Module):\n",
    "    \"\"\"Differentiable X-ray renderer implemented with trilinear interpolation.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        near=0.0,\n",
    "        far=1.0,\n",
    "        mode=\"bilinear\",\n",
    "        eps=1e-8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.near = near\n",
    "        self.far = far\n",
    "        self.mode = mode\n",
    "        self.eps = eps\n",
    "\n",
    "    def dims(self, volume):\n",
    "        return torch.tensor(volume.shape).to(volume) - 1\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        volume,\n",
    "        origin,\n",
    "        spacing,\n",
    "        source,\n",
    "        target,\n",
    "        n_points=500,\n",
    "        align_corners=True,\n",
    "        mask=None,\n",
    "    ):\n",
    "        # Get the raylength and reshape sources\n",
    "        raylength = (source - target + self.eps).norm(dim=-1).unsqueeze(1)\n",
    "        source = source[:, None, :, None, :] - origin\n",
    "        target = target[:, None, :, None, :] - origin\n",
    "\n",
    "        # Sample points along the rays and rescale to [-1, 1]\n",
    "        alphas = torch.linspace(self.near, self.far, n_points).to(volume)\n",
    "        alphas = alphas[None, None, None, :, None]\n",
    "        rays = source + alphas * (target - source)\n",
    "        rays = 2 * rays / (spacing * self.dims(volume)) - 1\n",
    "\n",
    "        # Reorder array to match torch conventions\n",
    "        volume = volume.permute(2, 1, 0)\n",
    "        if mask is not None:\n",
    "            mask = mask.permute(2, 1, 0)\n",
    "\n",
    "        # Render the DRR\n",
    "        batch_size = len(rays)\n",
    "        img = grid_sample(\n",
    "            volume[None, None, :, :, :].expand(batch_size, -1, -1, -1, -1),\n",
    "            rays,\n",
    "            mode=self.mode,\n",
    "            align_corners=align_corners,\n",
    "        )[:, 0, 0]\n",
    "\n",
    "        # Handle optional masking\n",
    "        if mask is None:\n",
    "            img = img.sum(dim=-1).unsqueeze(1)\n",
    "        else:\n",
    "            B, D, N = img.shape\n",
    "            C = mask.max().item() + 1\n",
    "            channels = grid_sample(\n",
    "                mask[None, None, :, :, :].expand(batch_size, -1, -1, -1, -1).float(),\n",
    "                rays,\n",
    "                mode=\"nearest\",\n",
    "                align_corners=align_corners,\n",
    "            ).long()[:, 0, 0]\n",
    "            img = (\n",
    "                torch.zeros(B, C, D)\n",
    "                .to(volume)\n",
    "                .scatter_add_(1, channels.transpose(-1, -2), img.transpose(-1, -2))\n",
    "            )\n",
    "\n",
    "        # Multiply by raylength\n",
    "        img *= raylength / n_points\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
