{
 "cells": [
  {
   "cell_type": "raw",
   "id": "bb4bed05",
   "metadata": {},
   "source": [
    "---\n",
    "title: data\n",
    "description: Load DICOM datasets as numpy arrays with voxel dimensions\n",
    "output-file: data.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9649072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec0581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nibabel.orientations import apply_orientation, axcodes2ornt, ornt_transform\n",
    "from torchio import LabelMap, ScalarImage, Subject\n",
    "from torchio.transforms import Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d813be4b-c664-4ca4-84f8-8d4eb6f154e5",
   "metadata": {},
   "source": [
    "CT scans in `DiffDRR` are stored using the `torchio.Subject` dataclass.\n",
    "`torchio` provides a convenient and consistent mechanism for reading volumes\n",
    "from a variety of formats and orientations. We canonicalize all volumes to \n",
    "the RAS+ coordinate space. In addition to reading an input volume, you can also pass\n",
    "the following to `diffdrr.data.read` when loading a subject:\n",
    "\n",
    "- `labelmap` : a 3D segmentation of the input volume\n",
    "- `labels` : a subset of structures from the labelmap that you want to render\n",
    "- `orientation` : a frame-of-reference change for the C-arm (currently, \"AP\" and \"PA\" are supported)\n",
    "- `bone_attenuation_multiplier` : a constant multiplier to the estimated density of bone voxels\n",
    "- `fiducials` : a tensor of 3D fiducial marks *in world coordinates*\n",
    "- `**kwargs` : any additional kwargs can be passed to the `torchio.Subject` and accessed as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_example_ct(\n",
    "    labels=None,\n",
    "    orientation=\"AP\",\n",
    "    bone_attenuation_multiplier=1.0,\n",
    "    **kwargs,\n",
    ") -> Subject:\n",
    "    \"\"\"Load an example chest CT for demonstration purposes.\"\"\"\n",
    "    datadir = Path(__file__).resolve().parent / \"data\"\n",
    "    volume = datadir / \"cxr.nii.gz\"\n",
    "    labelmap = datadir / \"mask.nii.gz\"\n",
    "    structures = pd.read_csv(datadir / \"structures.csv\")\n",
    "    return read(\n",
    "        volume,\n",
    "        labelmap,\n",
    "        labels,\n",
    "        orientation=orientation,\n",
    "        bone_attenuation_multiplier=bone_attenuation_multiplier,\n",
    "        structures=structures,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda997b-6e88-4bb1-bb9f-313302fe3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from diffdrr.pose import RigidTransform\n",
    "\n",
    "\n",
    "def read(\n",
    "    volume: str | Path | ScalarImage,  # CT volume\n",
    "    labelmap: str | Path | LabelMap = None,  # Labelmap for the CT volume\n",
    "    labels: int | list = None,  # Labels from the mask of structures to render\n",
    "    orientation: str | None = \"AP\",  # Frame-of-reference change\n",
    "    bone_attenuation_multiplier: float = 1.0,  # Scalar multiplier on density of high attenuation voxels\n",
    "    fiducials: torch.Tensor = None,  # 3D fiducials in world coordinates\n",
    "    transform: RigidTransform = None,  # RigidTransform to apply to the volume's affine\n",
    "    center_volume: bool = True,  # Move the volume's isocenter to the world origin\n",
    "    resample_target=None,  # Resampling resolution argument passed to torchio.transforms.Resample\n",
    "    **kwargs,  # Any additional information to be stored in the torchio.Subject\n",
    ") -> Subject:\n",
    "    \"\"\"\n",
    "    Read an image volume from a variety of formats, and optionally, any\n",
    "    given labelmap for the volume. Converts volume to a RAS+ coordinate\n",
    "    system and moves the volume isocenter to the world origin.\n",
    "    \"\"\"\n",
    "    # Read the volume\n",
    "    if isinstance(volume, ScalarImage):\n",
    "        pass\n",
    "    else:\n",
    "        volume = ScalarImage(volume)\n",
    "\n",
    "    # Read the mask if passed\n",
    "    if labelmap is not None:\n",
    "        if isinstance(labelmap, LabelMap):\n",
    "            mask = labelmap\n",
    "        else:\n",
    "            mask = LabelMap(labelmap)\n",
    "        _ = mask.data  # Load and cache the labelmap\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    # Optionally apply transform\n",
    "    if transform is not None:\n",
    "        T = transform.matrix[0].numpy()\n",
    "        volume = ScalarImage(tensor=volume.data, affine=T.dot(volume.affine))\n",
    "\n",
    "    # Convert the volume to density\n",
    "    density = transform_hu_to_density(volume.data, bone_attenuation_multiplier)\n",
    "    density = ScalarImage(tensor=density, affine=volume.affine)\n",
    "\n",
    "    # Frame-of-reference change\n",
    "    if orientation == \"AP\":\n",
    "        # Rotates the C-arm about the x-axis by 90 degrees\n",
    "        reorient = torch.tensor(\n",
    "            [\n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, -1, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 0, 1],\n",
    "            ],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "    elif orientation == \"PA\":\n",
    "        # Rotates the C-arm about the x-axis by 90 degrees \n",
    "        # Reverses the direction of the y-axis\n",
    "        reorient = torch.tensor(\n",
    "            [\n",
    "                [1, 0, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 0, 1],\n",
    "            ],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "    elif orientation is None:\n",
    "        # Identity transform\n",
    "        reorient = torch.tensor(\n",
    "            [\n",
    "                [1, 0, 0, 0],\n",
    "                [0, 1, 0, 0],\n",
    "                [0, 0, 1, 0],\n",
    "                [0, 0, 0, 1],\n",
    "            ],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized orientation {orientation}\")\n",
    "\n",
    "    # Package the subject\n",
    "    subject = Subject(\n",
    "        volume=volume,\n",
    "        mask=mask,\n",
    "        orientation=orientation,\n",
    "        reorient=reorient,\n",
    "        density=density,\n",
    "        fiducials=fiducials,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    # Move the subject's isocenter to the origin in world coordinates\n",
    "    if center_volume:\n",
    "        subject = canonicalize(subject)\n",
    "\n",
    "    # Apply mask\n",
    "    if labels is not None:\n",
    "        if isinstance(labels, int):\n",
    "            labels = [labels]\n",
    "        if subject.volume.orientation == subject.mask.orientation:\n",
    "            mask = torch.any(\n",
    "                torch.stack([subject.mask.data.squeeze() == idx for idx in labels]),\n",
    "                dim=0,\n",
    "            )\n",
    "        else:\n",
    "            # If the mask does not have the same orientation, transform the mask data\n",
    "            # to match the orientation of the volume data\n",
    "            transform = ornt_transform(\n",
    "                axcodes2ornt(subject.mask.orientation),\n",
    "                axcodes2ornt(subject.volume.orientation),\n",
    "            )\n",
    "            mask = torch.any(\n",
    "                torch.stack(\n",
    "                    [\n",
    "                        torch.tensor(\n",
    "                            apply_orientation(subject.mask.data.squeeze(), transform)\n",
    "                            == idx\n",
    "                        )\n",
    "                        for idx in labels\n",
    "                    ]\n",
    "                ),\n",
    "                dim=0,\n",
    "            )\n",
    "\n",
    "        # Mask all volumes, unless error, then just mask the density\n",
    "        try:\n",
    "            subject.volume.data = subject.volume.data * mask\n",
    "            subject.mask.data = subject.mask.data * mask\n",
    "            subject.density.data = subject.density.data * mask\n",
    "        except:\n",
    "            subject.density.data = subject.density.data * mask\n",
    "\n",
    "    # Apply resample\n",
    "    if resample_target is not None:\n",
    "        resample = Resample(resample_target)\n",
    "        subject = resample(subject)\n",
    "\n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ad014-b2ae-41b9-8b65-e4ca865e19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from diffdrr.pose import RigidTransform\n",
    "\n",
    "\n",
    "def canonicalize(subject):\n",
    "    # Get the original affine matrix\n",
    "    affine_original = torch.from_numpy(subject.volume.affine)\n",
    "\n",
    "    # Move the Subject's isocenter to the origin in world coordinates\n",
    "    for image in subject.get_images(intensity_only=False):\n",
    "        isocenter = image.get_center()\n",
    "        Tinv = np.array(\n",
    "            [\n",
    "                [1.0, 0.0, 0.0, -isocenter[0]],\n",
    "                [0.0, 1.0, 0.0, -isocenter[1]],\n",
    "                [0.0, 0.0, 1.0, -isocenter[2]],\n",
    "                [0.0, 0.0, 0.0, 1.0],\n",
    "            ]\n",
    "        )\n",
    "        image.affine = Tinv.dot(image.affine)\n",
    "\n",
    "    # If fiducials are provided (in world coordinates), reorient them\n",
    "    if subject.fiducials is not None:\n",
    "        affine_new = torch.tensor(image.affine)\n",
    "        affine = affine_new @ affine_original.inverse()\n",
    "        affine = affine.to(subject.fiducials)\n",
    "        affine = RigidTransform(affine)\n",
    "        subject.fiducials = affine(subject.fiducials)\n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2941e0-cb0d-44c7-9b00-4dad1ced447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def transform_hu_to_density(volume, bone_attenuation_multiplier):\n",
    "    # volume can be loaded as int16, need to convert to float32 to use float bone_attenuation_multiplier\n",
    "    volume = volume.to(torch.float32)\n",
    "    air = torch.where(volume <= -800)\n",
    "    soft_tissue = torch.where((-800 < volume) & (volume <= 350))\n",
    "    bone = torch.where(350 < volume)\n",
    "\n",
    "    density = torch.empty_like(volume)\n",
    "    density[air] = volume[soft_tissue].min()\n",
    "    density[soft_tissue] = volume[soft_tissue]\n",
    "    density[bone] = volume[bone] * bone_attenuation_multiplier\n",
    "    density -= density.min()\n",
    "    density /= density.max()\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1da1619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa105ac3-c05d-47f9-8c14-2d5c14ae88b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
