{
 "cells": [
  {
   "cell_type": "raw",
   "id": "c823ed02",
   "metadata": {},
   "source": [
    "---\n",
    "title: metrics\n",
    "description: Loss functions for registration and reconstruction tasks\n",
    "output-file: metrics.html\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff7dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b08ec-3331-45ee-a1d7-cc9b21ef5ca9",
   "metadata": {},
   "source": [
    "## Image similarity metrics\n",
    "\n",
    "Compute the similarity between a fixed X-ray $\\mathbf I$ and a moving X-ray $\\mathbf{\\hat I}$, where $\\mathbf{\\hat I}$ is rendered from an estimated camera pose (registration) or volume (reconstruction).\n",
    "\n",
    "We implement patchwise variants of the following metrics:\n",
    "\n",
    "- Normalized Cross Correlation (NCC)\n",
    "- Multiscale Normalized Cross Correlation (mNCC)\n",
    "- Gradient Normalized Cross Correlation (gNCC)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bcd37974-d90c-4115-a717-b17f3725630d",
   "metadata": {},
   "source": [
    "::: {.callout-tip}\n",
    "If `patch_size=None`, the similarity metric is computed over the entire image.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b3608-8d2a-43b6-b902-9f905877dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "def to_patches(x, patch_size):\n",
    "    x = x.unfold(2, patch_size, step=1).unfold(3, patch_size, step=1).contiguous()\n",
    "    return rearrange(x, \"b c p1 p2 h w -> b (c p1 p2) h w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28930479-d8e6-4859-b5de-38a5350f510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NormalizedCrossCorrelation2d(torch.nn.Module):\n",
    "    \"\"\"Compute Normalized Cross Correlation between two batches of images.\"\"\"\n",
    "\n",
    "    def __init__(self, patch_size=None, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        if self.patch_size is not None:\n",
    "            x1 = to_patches(x1, self.patch_size)\n",
    "            x2 = to_patches(x2, self.patch_size)\n",
    "        assert x1.shape == x2.shape, \"Input images must be the same size\"\n",
    "        _, c, h, w = x1.shape\n",
    "        x1, x2 = self.norm(x1), self.norm(x2)\n",
    "        score = torch.einsum(\"b...,b...->b\", x1, x2)\n",
    "        score /= c * h * w\n",
    "        return score\n",
    "\n",
    "    def norm(self, x):\n",
    "        mu = x.mean(dim=[-1, -2], keepdim=True)\n",
    "        var = x.var(dim=[-1, -2], keepdim=True, correction=0) + self.eps\n",
    "        std = var.sqrt()\n",
    "        return (x - mu) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06c00d-830c-48d9-b394-07cc83c1ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MultiscaleNormalizedCrossCorrelation2d(torch.nn.Module):\n",
    "    \"\"\"Compute Normalized Cross Correlation between two batches of images at multiple scales.\"\"\"\n",
    "\n",
    "    def __init__(self, patch_sizes=[None], patch_weights=[1.0], eps=1e-5):\n",
    "        super().__init__()\n",
    "\n",
    "        assert len(patch_sizes) == len(patch_weights), \"Each scale must have a weight\"\n",
    "        self.nccs = [\n",
    "            NormalizedCrossCorrelation2d(patch_size) for patch_size in patch_sizes\n",
    "        ]\n",
    "        self.patch_weights = patch_weights\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        scores = []\n",
    "        for weight, ncc in zip(self.patch_weights, self.nccs):\n",
    "            scores.append(weight * ncc(x1, x2))\n",
    "        return torch.stack(scores, dim=0).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6317e99-8a0a-4dce-959f-904c21595d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "from torchvision.transforms.functional import gaussian_blur\n",
    "\n",
    "\n",
    "class Sobel(torch.nn.Module):\n",
    "    def __init__(self, sigma):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "        self.filter = torch.nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=2,  # X- and Y-gradients\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,  # Return images of the same size as inputs\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        Gx = torch.tensor([[1, 0, -1], [2, 0, -2], [1, 0, -1]]).to(torch.float32)\n",
    "        Gy = torch.tensor([[1, 2, 1], [0, 0, 0], [-1, -2, -1]]).to(torch.float32)\n",
    "        G = torch.stack([Gx, Gy]).unsqueeze(1)\n",
    "        self.filter.weight = torch.nn.Parameter(G, requires_grad=False)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = gaussian_blur(img, 5, self.sigma)\n",
    "        x = self.filter(img)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc39dd1d-ab40-4f7b-926d-dff305b9ab69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GradientNormalizedCrossCorrelation2d(NormalizedCrossCorrelation2d):\n",
    "    \"\"\"Compute Normalized Cross Correlation between the image gradients of two batches of images.\"\"\"\n",
    "\n",
    "    def __init__(self, patch_size=None, sigma=1.0, **kwargs):\n",
    "        super().__init__(patch_size, **kwargs)\n",
    "        self.sobel = Sobel(sigma)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return super().forward(self.sobel(x1), self.sobel(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c67f91-d50f-4b68-a24a-58390558837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0019, -0.0004,  0.0035, -0.0198, -0.0078, -0.0175,  0.0171,  0.0019])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "x1 = torch.randn(8, 1, 128, 128)\n",
    "x2 = torch.randn(8, 1, 128, 128)\n",
    "\n",
    "ncc = NormalizedCrossCorrelation2d()\n",
    "ncc(x1, x2)\n",
    "\n",
    "ncc = NormalizedCrossCorrelation2d(eps=1e-1)\n",
    "ncc(x1, x2)\n",
    "\n",
    "ncc = NormalizedCrossCorrelation2d(patch_size=9)\n",
    "ncc(x1, x2)\n",
    "\n",
    "msncc = MultiscaleNormalizedCrossCorrelation2d(\n",
    "    patch_sizes=[9, None], patch_weights=[0.5, 0.5]\n",
    ")\n",
    "msncc(x1, x2)\n",
    "\n",
    "gncc = GradientNormalizedCrossCorrelation2d()\n",
    "gncc(x1, x2)\n",
    "\n",
    "gncc = GradientNormalizedCrossCorrelation2d(patch_size=9)\n",
    "gncc(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec69035d-05b4-4b76-b88e-10b6e0920fe9",
   "metadata": {},
   "source": [
    "## Geodesic distances for SE(3)\n",
    "\n",
    "One can define geodesic pseudo-distances on $\\mathbf{SO}(3)$ and $\\mathbf{SE}(3)$.[^1] This let's us measure registration error (in radians and millimeters, respectively) on poses, rather than needed to compute the projection of fiducials.\n",
    "\n",
    "We implement two geodesics on $\\mathbf{SE}(3)$:\n",
    "\n",
    "- The logarithmic geodesic\n",
    "- The double geodesic\n",
    "\n",
    "[^1]: [https://vnav.mit.edu/material/04-05-LieGroups-notes.pdf](https://vnav.mit.edu/material/04-05-LieGroups-notes.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f251c-4866-4bb7-bf70-29d2feda8441",
   "metadata": {},
   "source": [
    "### Logarithmic Geodesic\n",
    "\n",
    "Given two rotation matrices $\\mathbf R_A, \\mathbf R_B \\in \\mathbf{SO}(3)$, the angular distance between their axes of rotation is\n",
    "\n",
    "$$\n",
    "    d_\\theta(\\mathbf R_A, \\mathbf R_B) \n",
    "    = \\arccos \\left( \\frac{\\mathrm{trace}(\\mathbf R_A^T \\mathbf R_B) - 1}{2} \\right)\n",
    "    = \\| \\log (\\mathbf R_A^T \\mathbf R_B) \\| \\,,\n",
    "$$\n",
    "\n",
    "where $\\log(\\cdot)$ is the logarithm map on $\\mathbf{SO}(3)$.[^2]\n",
    "Using the logarithm map on $\\mathbf{SE}(3)$, this generalizes to a geodesic loss function on camera poses ${\\mathbf T}_A, {\\mathbf T}_B \\in \\mathbf{SE}(3)$:\n",
    "\n",
    "$$\n",
    "    \\mathcal L_{\\mathrm{log}}({\\mathbf T}_A, {\\mathbf T}_B) = \\| \\log({\\mathbf T}_A^{-1} {\\mathbf T}_B) \\| \\,.\n",
    "$$\n",
    "\n",
    "[^2]: [https://www.cs.cmu.edu/~cga/dynopt/readings/Rmetric.pdf](https://www.cs.cmu.edu/~cga/dynopt/readings/Rmetric.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b691875b-c136-4ea5-8551-fab45530e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from diffdrr.pose import RigidTransform, convert\n",
    "\n",
    "\n",
    "class LogGeodesicSE3(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Calculate the distance between transforms in the log-space of SE(3).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pose_1: RigidTransform,\n",
    "        pose_2: RigidTransform,\n",
    "    ) -> Float[torch.Tensor, \"b\"]:\n",
    "        return pose_2.compose(pose_1.inverse()).get_se3_log().norm(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df891bb5-44f6-4cfa-b9e6-06e32b0a5aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7354])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SE(3) distance\n",
    "geodesic_se3 = LogGeodesicSE3()\n",
    "\n",
    "pose_1 = convert(\n",
    "    torch.tensor([[0.1, 1.0, torch.pi]]),\n",
    "    torch.ones(1, 3),\n",
    "    parameterization=\"euler_angles\",\n",
    "    convention=\"ZYX\",\n",
    ")\n",
    "pose_2 = convert(\n",
    "    torch.tensor([[0.1, 1.1, torch.pi]]),\n",
    "    torch.zeros(1, 3),\n",
    "    parameterization=\"euler_angles\",\n",
    "    convention=\"ZYX\",\n",
    ")\n",
    "\n",
    "geodesic_se3(pose_1, pose_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfdc8eba-cc2b-4ac8-a6d5-99f4d3715c2a",
   "metadata": {},
   "source": [
    "## Double Geodesic\n",
    "\n",
    "We can also formulate a geodesic distance on $\\mathbf{SE}(3)$ with units of length. Using the camera's focal length $f$, we convert the angular distance to an arc length:\n",
    "\n",
    "$$\n",
    "    d_\\theta(\\mathbf R_A, \\mathbf R_B; f) = \\frac{f}{2} d_\\theta(\\mathbf R_A, \\mathbf R_B) \\,.\n",
    "$$\n",
    "\n",
    "When combined with the Euclidean distance on the translations $d_t(\\mathbf t_A, \\mathbf t_B) = \\| \\mathbf t_A - \\mathbf t_B \\|$, this yields the *double geodesic* loss on $\\mathbf{SE}(3)$:[^3]\n",
    "\n",
    "$$\n",
    "    \\mathcal L_{\\mathrm{geo}}({\\mathbf T}_A, {\\mathbf T}_B; f) = \\sqrt{d^2_\\theta(\\mathbf R_A, \\mathbf R_B; f) + d^2_t(\\mathbf t_A, \\mathbf t_B)} \\,.\n",
    "$$\n",
    "\n",
    "[^3]: [https://rpk.lcsr.jhu.edu/wp-content/uploads/2017/08/Partial-Bi-Invariance-of-SE3-Metrics1.pdf](https://rpk.lcsr.jhu.edu/wp-content/uploads/2017/08/Partial-Bi-Invariance-of-SE3-Metrics1.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac6d6f4-462b-47ea-b25b-8a2518749e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from diffdrr.pose import so3_log_map\n",
    "\n",
    "\n",
    "class DoubleGeodesicSE3(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Calculate the angular and translational geodesics between two SE(3) transformation matrices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sdd: float,  # Source-to-detector distance\n",
    "        eps: float = 1e-6,  # Avoid overflows in sqrt\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.sdr = sdd / 2\n",
    "        self.eps = eps\n",
    "\n",
    "        self.rot_geo = lambda r1, r2: self.sdr * so3_log_map(r1.transpose(-1, -2) @ r2).norm(dim=-1)\n",
    "        self.xyz_geo = lambda t1, t2: (t1 - t2).norm(dim=-1)\n",
    "\n",
    "    def forward(self, pose_1: RigidTransform, pose_2: RigidTransform):\n",
    "        r1, t1 = pose_1.convert(\"matrix\")\n",
    "        r2, t2 = pose_2.convert(\"matrix\")\n",
    "        rot = self.rot_geo(r1, r2)\n",
    "        xyz = self.xyz_geo(t1, t2)\n",
    "        dou = (rot.square() + xyz.square() + self.eps).sqrt()\n",
    "        return rot, xyz, dou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be429e-7bfa-4663-b310-39568b1ca6fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([51.0000]), tensor([1.7321]), tensor([51.0294]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Angular distance and translational distance both in mm\n",
    "double_geodesic = DoubleGeodesicSE3(1020.0)\n",
    "\n",
    "pose_1 = convert(\n",
    "    torch.tensor([[0.1, 1.0, torch.pi]]),\n",
    "    torch.ones(1, 3),\n",
    "    parameterization=\"euler_angles\",\n",
    "    convention=\"ZYX\",\n",
    ")\n",
    "pose_2 = convert(\n",
    "    torch.tensor([[0.1, 1.1, torch.pi]]),\n",
    "    torch.zeros(1, 3),\n",
    "    parameterization=\"euler_angles\",\n",
    "    convention=\"ZYX\",\n",
    ")\n",
    "\n",
    "double_geodesic(pose_1, pose_2)  # Angular, translational, double geodesics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ae1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538daf03-4a98-405e-9ddf-448b3c831af7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
